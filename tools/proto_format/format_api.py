#!/usr/bin/env python3

# Mangle protoxform and protoprint artifacts.

import argparse
from collections import defaultdict
import os
import pathlib
import re
import shutil
import string
import subprocess
import tarfile
import tempfile

from tools.proto_format.data import data

DEFAULT_BUILD_TARGET = 'pkg'

# These .proto import direct path prefixes are already handled by
# api_proto_package() as implicit dependencies.
API_BUILD_SYSTEM_IMPORT_PREFIXES = [
    'google/api/annotations.proto',
    'google/protobuf/',
    'google/rpc/status.proto',
    'validate/validate.proto',
]

# Each of the following contrib extensions are allowed to be in the v3 namespace. Indicate why.
CONTRIB_V3_ALLOW_LIST = [
    # Extensions moved from core to contrib.
    'envoy.extensions.filters.http.dynamo.v3',
    'envoy.extensions.filters.http.squash.v3',
    'envoy.extensions.filters.network.client_ssl_auth.v3',
    'envoy.extensions.filters.network.generic_proxy.action.v3',
    'envoy.extensions.filters.network.generic_proxy.codecs.dubbo.v3',
    'envoy.extensions.filters.network.generic_proxy.codecs.http1.v3',
    'envoy.extensions.filters.network.generic_proxy.codecs.kafka.v3',
    'envoy.extensions.filters.network.generic_proxy.matcher.v3',
    'envoy.extensions.filters.network.generic_proxy.router.v3',
    'envoy.extensions.filters.network.generic_proxy.v3',
    'envoy.extensions.filters.network.kafka_broker.v3',
    'envoy.extensions.filters.network.mysql_proxy.v3',
    'envoy.extensions.filters.network.rocketmq_proxy.v3',
]

BUILD_FILE_HEADER = """# DO NOT EDIT. This file is generated by tools/proto_format/proto_sync.py.

load("@envoy_api//bazel:api_build_system.bzl", "api_proto_package")

licenses(["notice"])  # Apache 2"""

API_PROTO_PACKAGE_TEMPLATE = string.Template('api_proto_package($fields)')

VERSIONING_BUILD_FILE_TEMPLATE = string.Template(
    """# DO NOT EDIT. This file is generated by tools/proto_format/proto_sync.py.

load("@rules_proto//proto:defs.bzl", "proto_library")

licenses(["notice"])  # Apache 2

# This tracks active development versions of protos.
proto_library(
    name = "active_protos",
    visibility = ["//visibility:public"],
    deps = [
$active_pkgs    ],
)

# This tracks frozen versions of protos.
proto_library(
    name = "frozen_protos",
    visibility = ["//visibility:public"],
    deps = [
$frozen_pkgs    ],
)
""")

IMPORT_REGEX = re.compile(r'import "(.*)";')
SERVICE_REGEX = re.compile(r'service \w+ {')
PACKAGE_REGEX = re.compile(r'\npackage ([a-z0-9_\.]*);')
PREVIOUS_MESSAGE_TYPE_REGEX = re.compile(r'previous_message_type\s+=\s+"([^"]*)";')


class ProtoSyncError(Exception):
    pass


class RequiresReformatError(ProtoSyncError):

    def __init__(self, message):
        # This doesnt make sense the only time it can be triggered is when you are already running this.
        super(RequiresReformatError, self).__init__(
            '%s; either run ./ci/do_ci.sh fix_proto_format or ./tools/proto_format/proto_format.sh fix to reformat.\n'
            % message)


def get_directory_from_package(package):
    """Get directory path from package name or full qualified message name

    Args:
        package: the full qualified name of package or message.
    """
    return '/'.join(s for s in package.split('.') if s and s[0].islower())


def get_destination_path(src):
    """Obtain destination path from a proto file path by reading its package statement.

    Args:
        src: source path
    """
    src_path = pathlib.Path(src)
    contents = src_path.read_text(encoding='utf8')
    matches = PACKAGE_REGEX.findall(contents)
    if len(matches) != 1:
        raise RequiresReformatError(
            f"Expect {src} has only one package declaration but has {len(matches)}\n{contents}")
    package = matches[0]
    dst_path = pathlib.Path(
        get_directory_from_package(package)).joinpath(src_path.name.split('.')[0] + ".proto")
    # contrib API files have the standard namespace but are in a contrib folder for clarity.
    # The following prepends contrib for contrib packages so we wind up with the real final path.
    if 'contrib' in src:
        if 'v3alpha' not in package and 'v4alpha' not in package and package not in CONTRIB_V3_ALLOW_LIST:
            raise ProtoSyncError(
                "contrib extension package '{}' does not use v3alpha namespace. "
                "Add to CONTRIB_V3_ALLOW_LIST with an explanation if this is on purpose.".format(
                    package))

        dst_path = pathlib.Path('contrib').joinpath(dst_path)
    # Non-contrib can not use alpha.
    if not 'contrib' in src:
        if (not 'v2alpha' in package and not 'v1alpha1' in package) and 'alpha' in package:
            raise ProtoSyncError(
                "package '{}' uses an alpha namespace. This is not allowed. Instead mark with "
                "(xds.annotations.v3.file_status).work_in_progress or related annotation.".format(
                    package))
    return dst_path


def sync_proto_file(srcs, dst):
    """Pretty-print a proto descriptor from protoxform.py Bazel cache artifacts."

    Args:
        dst_srcs: destination/sources path tuple.
    """
    assert (len(srcs) > 0)
    # If we only have one candidate source for a destination, just pretty-print.
    if len(srcs) == 1:
        src = srcs[0]
    else:
        # We should only see an active and next major version candidate from
        # previous version today.
        assert (len(srcs) == 2)
        src = [s for s in srcs if s.endswith('active_or_frozen.proto')][0]
    shutil.copy(src, dst)
    rel_dst_path = get_destination_path(src)
    return ['//%s:pkg' % str(rel_dst_path.parent)]


def get_import_deps(proto_path, api_root, targets):
    """Obtain the Bazel dependencies for the import paths from a .proto file.

    Args:
        proto_path: full path of .proto.
        api_root: root path of these proto files.
        targets: dict of source proto to target.

    Returns:
        A list of Bazel targets reflecting the imports in the .proto at proto_path.
    """
    imports = []

    rel_path = os.path.relpath(proto_path, api_root)

    with open(proto_path, 'r', encoding='utf8') as f:
        for line in f:
            match = re.match(IMPORT_REGEX, line)
            if match:
                import_path = match.group(1)
                # We can ignore imports provided implicitly by api_proto_package().
                if any(import_path.startswith(p) for p in API_BUILD_SYSTEM_IMPORT_PREFIXES):
                    continue
                # Special case handling for UDPA annotations.
                if import_path.startswith('udpa/annotations/'):
                    imports.append('@com_github_cncf_xds//udpa/annotations:pkg')
                    continue
                if import_path.startswith('xds/type/matcher/v3/'):
                    imports.append('@com_github_cncf_xds//xds/type/matcher/v3:pkg')
                    continue
                if import_path.startswith('xds/type/v3/'):
                    imports.append('@com_github_cncf_xds//xds/type/v3:pkg')
                    continue
                # Special case for handling XDS annotations.
                if import_path.startswith('xds/annotations/v3/'):
                    imports.append('@com_github_cncf_xds//xds/annotations/v3:pkg')
                    continue
                # Special case handling for XDS core.
                if import_path.startswith('xds/core/v3/'):
                    imports.append('@com_github_cncf_xds//xds/core/v3:pkg')
                    continue
                # Explicit remapping for external deps, compute paths for envoy/*.
                if import_path in data["external_proto_deps"]["imports"]:
                    imports.append(data["external_proto_deps"]["imports"][import_path])
                    continue
                if import_path.startswith('envoy/') or import_path.startswith('contrib/'):
                    # Ignore package internal imports.
                    if os.path.dirname(proto_path).endswith(os.path.dirname(import_path)):
                        continue
                    imports.append(f'//{os.path.dirname(import_path)}:{targets[import_path]}')
                    continue
                raise ProtoSyncError(
                    'Unknown import path mapping for %s, please update the mappings in tools/proto_format/proto_sync.py.\n'
                    % import_path)
    return imports


def has_services(proto_path):
    """Does a .proto file have any service definitions?

    Args:
        proto_path: path to .proto.

    Returns:
        True iff there are service definitions in the .proto at proto_path.
    """
    with open(proto_path, 'r', encoding='utf8') as f:
        for line in f:
            if re.match(SERVICE_REGEX, line):
                return True
    return False


def build_file_contents(path, files, api_root, targets):
    """Compute the canonical BUILD contents for an api/ proto directory.

    Args:
        path: base path to directory.
        files: a list of files in the directory.
        api_root: the root path of these files.
        targets: dict of source proto to target.

    Returns:
        A string containing the canonical BUILD file content for root.
    """

    # Filter the .proto files to different targets
    target_to_proto_files = defaultdict(list)

    for f in files:
        if not f.endswith('.proto'):
            continue

        rel_path = os.path.relpath(os.path.join(path, f), api_root)
        if rel_path not in targets:
            continue

        target_to_proto_files[targets[rel_path]].append(f)

    contents = BUILD_FILE_HEADER

    need_sources = len(target_to_proto_files) > 1

    for target, proto_files in target_to_proto_files.items():
        deps = set(sum([get_import_deps(os.path.join(path, f), api_root, targets) for f in proto_files], []))
        _has_services = any(has_services(os.path.join(path, f)) for f in proto_files)
        fields = []

        if target != DEFAULT_BUILD_TARGET:
            fields.append('    name = "%s",' % target)
            # Add suffix to go import path to ensure multiple targets of same package
            # will not conflict in generated go code.
            fields.append('    go_import_path_suffix = "/%s",' % target)
        if _has_services:
            fields.append('    has_services = True,')
        if need_sources:
            fields.append('    srcs = [')
            for f in sorted(proto_files, key=build_order_key):
                fields.append('        "%s",' % f)
            fields.append('    ],')

        if deps:
            if len(deps) == 1:
                fields.append('    deps = ["%s"],' % list(deps)[0])
            else:
                fields.append('    deps = [')
                for d in sorted(deps, key=build_order_key):
                    fields.append('        "%s",' % d)
                fields.append('    ],')

        formatted_fields = '\n' + '\n'.join(fields) + '\n' if fields else ''
        contents = contents + '\n\n' + API_PROTO_PACKAGE_TEMPLATE.substitute(fields=formatted_fields)

    return contents + '\n'

def sync_build_files(cmd, api_root, targets):
    """Diff or in-place update api/ BUILD files.

    Args:
        cmd: 'check' or 'fix'.
    """
    for path, dirs, files in os.walk(str(api_root)):
        is_proto_dir = any(f.endswith('.proto') for f in files)
        if not is_proto_dir:
            continue

        build_contents = build_file_contents(path, files, api_root, targets)
        build_path = os.path.join(path, 'BUILD')
        with open(build_path, 'w') as f:
            f.write(build_contents)


# Key sort function to achieve consistent results with buildifier.
def build_order_key(key):
    return key.replace(':', '!')


def deps_format(pkgs):
    if not pkgs:
        return ''
    return '\n'.join('        "%s",' % p for p in sorted(pkgs, key=build_order_key)) + '\n'


# Find packages with a given package version status in a given API tree root.
def find_pkgs(package_version_status, api_root, targets):
    used_targets = set()
    try:
        active_files = subprocess.check_output(
            ['grep', '-l', '-r',
             'package_version_status = %s;' % package_version_status,
             api_root]).decode().strip().split('\n')
        api_protos = [f for f in active_files if f.endswith('.proto')]

        for f in api_protos:
            rel_path = os.path.relpath(f, api_root)
            dir_name = os.path.dirname(rel_path)
            if rel_path in targets:
                used_targets.add(f'//{dir_name.replace('.', '/')}:{targets[rel_path]}')
    except subprocess.CalledProcessError:
        api_protos = []
    return used_targets

def proto_to_target(printed_dir):
    # The target of a .proto file is the top level directory under printed_dir
    # (The api_proto_plugin_impl added the target name as top level directory).
    #
    # Walk up the directory tree until we find all proto files and record its
    # target.
    targets = {}
    for root, dirs, files in os.walk(printed_dir):
        # The proto files in the printed_dir will end with .proto.proto.
        # TODO(wbpcode): clean up all these tools format.
        proto_files = [f for f in files if f.endswith('.proto.proto')]
        if not proto_files:
            continue

        # Get relative path of every .proto file to printed_dir. For example:
        #   pkg/envoy/config/core/v3/base.proto
        #   pkg/envoy/type/v3/percent.proto
        #   hash_policy/envoy/type/v3/hash_policy.proto
        #
        rel_paths = [os.path.relpath(os.path.join(root, f), printed_dir) for f in proto_files]

        for rel_path in rel_paths:
            # Extract target name from the relative path.
            target_and_proto = rel_path.split('/', 1)
            # Remove redundant .proto suffix.
            targets[target_and_proto[1].removesuffix(".proto")] = target_and_proto[0]

    return targets


def format_api(mode, outfile, xformed, printed, build_file):

    with tempfile.TemporaryDirectory() as tmp:
        dst_dir = pathlib.Path(tmp)
        printed_dir = dst_dir.joinpath("printed")
        printed_dir.mkdir(parents=True)
        with tarfile.open(printed) as tar:
            tar.extractall(printed_dir)

        xformed_dir = dst_dir.joinpath("xformed")
        xformed_dir.mkdir()
        with tarfile.open(xformed) as tar:
            tar.extractall(xformed_dir)

        targets = proto_to_target(printed_dir)

        dst_src_paths = defaultdict(list)

        for label in data["proto_targets"]:
            # The _lable is the relative path of the .proto to the API root directly.
            _label = label[len('@@envoy_api//'):].replace(':', '/')
            for suffix in ["active_or_frozen", "next_major_version_candidate"]:
                xpath = xformed_dir.joinpath(f"{targets[_label]}/{_label}.{suffix}.proto")
                path = printed_dir.joinpath(f"{targets[_label]}/{_label}.proto")

                if xpath.exists() and os.stat(xpath).st_size > 0:
                    target = dst_dir.joinpath(_label)
                    target.parent.mkdir(exist_ok=True, parents=True)
                    dst_src_paths[str(target)].append(str(path))

        for k, v in dst_src_paths.items():
            sync_proto_file(v, k)
        sync_build_files(mode, dst_dir, targets)

        # Add the build files
        dst_dir.joinpath("BUILD").write_bytes(build_file.read_bytes())

        active_pkgs = find_pkgs('ACTIVE', dst_dir, targets)
        frozen_pkgs = find_pkgs('FROZEN', dst_dir, targets)

        dst_dir.joinpath("versioning").mkdir(exist_ok=True)
        dst_dir.joinpath("versioning/BUILD").write_text(
            VERSIONING_BUILD_FILE_TEMPLATE.substitute(
                active_pkgs=deps_format(active_pkgs), frozen_pkgs=deps_format(frozen_pkgs)))

        shutil.rmtree(str(printed_dir))
        shutil.rmtree(str(xformed_dir))
        with tarfile.open(outfile, "w:gz") as tar:
            tar.add(dst_dir, arcname=".")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', choices=['check', 'fix'])
    parser.add_argument('--outfile')
    parser.add_argument('--protoprinted')
    parser.add_argument('--xformed')
    parser.add_argument('--build_file')
    args = parser.parse_args()

    format_api(
        args.mode, str(pathlib.Path(args.outfile).absolute()),
        str(pathlib.Path(args.xformed).absolute()), args.protoprinted,
        pathlib.Path(args.build_file))
